# Henry Zhang's Paper Reading Logs

Welcome to my personal repository for recording and summarizing research papers I've read.  
My focus areas include:
- **Vision-Language Models (VLMs)**
- **Reinforcement Learning for Multimodal Reasoning**
- **Mixture-of-Experts (MoE)**

---

## Table of Contents
- [📅 Reading Log](#-reading-log)
- [🧱 Template for New Logs](#-template-for-new-logs)
- [🧩 Legend](#-legend)

---

## Why Reading Log? 

As mentioned in [this insightful post](https://www.xiaohongshu.com/discovery/item/68fc7fa90000000003035c7e?source=webshare),  
> “**Scientific research begins with reading papers.**”  
> Typically, each research area has **10–20 core papers** that should be studied thoroughly,  
> and around **40–50 important papers** that deserve focused reading.  

Following this philosophy — and guided by GPT-5’s recommendations —  
I maintain this structured log to record my progress during different stages of reading and exploration.

## 📅 Reading Log

| Date | Paper | Year | Notes | Status |
|------|--------|------|--------|---------|
| 2025-10-29 | **Attention Is All You Need** | 2017 | Introduced the Transformer; foundation for all subsequent sequence models. | ✅ Done |
| 2025-10-30 | **BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding** | 2019 | Bidirectional pretraining with Masked LM and NSP; milestone in NLP. | ✅ Done |
| 2025-10-30 | **RoBERTa: A Robustly Optimized BERT Pretraining Approach** | 2019 | Improved training dynamics and data efficiency; stronger baselines. | ✅ Done |
| 2025-10-30 | **ALBERT: A Lite BERT for Self-supervised Learning of Language Representations** | 2020 | Introduced parameter sharing and embedding factorization for efficiency. | ✅ Done |



---

## 🧱 Template for New Logs

> 🧩 Copy this structure when adding a new paper to the log.

| Date | Paper | Venue | Keywords | Status | Type | Notes |
|------|--------|--------|----------|---------|-------|--------|
| YYYY-MM-DD | **[Paper Title]** | [Conference / Journal] | [Key Concepts, Methods, Datasets] | ✅ Done / 🕒 Reading / 📖 Planned | 🔑 Core / 🧩 Topic / ⚙️ Efficiency / 🚀 Focus | Brief summary, thoughts, or reflections. |

---

## 🧩 Legend

| Symbol | Meaning |
|:-------|:---------|
| ✅ Done | Fully read and summarized |
| 🕒 Reading | Currently reading |
| 📖 Planned | Planned for future reading |
| 🔑 Core | Foundational or highly influential paper |
| 🧩 Topic | Thematically relevant work |
| ⚙️ Efficiency | Lightweight or optimization-oriented paper |
| 🚀 Focus | Central to my ongoing research direction |

---

## One more thing 
I hope these reading records can serve as a useful reference and help fellow newcomers navigate the landscape of research reading more effectively 🚀 🚀 🚀 .
